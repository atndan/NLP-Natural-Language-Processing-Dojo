{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5a52b31-e2b5-4893-88b6-296f03ddb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9013d3bf-c866-4d69-b505-530d6c80061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import business artical\n",
    "import os\n",
    "text = []\n",
    "for root, dirs, files in os.walk(\"business\"):\n",
    "   for file in files:\n",
    "       if file.endswith(\".txt\"):\n",
    "            filename = os.path.join(root, file) \n",
    "            with open(filename, 'r', encoding=\"utf8\", errors='ignore') as infile:\n",
    "                intext = ''\n",
    "                for line in infile:\n",
    "                    intext = intext + ' ' + line.replace(\"\\n\", '')\n",
    "                text.append(intext)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd59a14e-7d3a-4a10-8ad7-8c5061c4952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(text, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf04be50-66bc-459c-9109-e4aba90eca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "150bf046-cc64-48f7-9500-30c152a17fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Japan narrowly escapes recession  Japan\\'s economy teetered on the brink of a technical recession in the three months to September, figures show.  Revised figures indicated growth of just 0.1% - and a similar-sized contraction in the previous quarter. On an annual basis, the data suggests annual growth of just 0.2%, suggesting a much more hesitant recovery than had previously been thought. A common technical definition of a recession is two successive quarters of negative growth.  The government was keen to play down the worrying implications of the data. \"I maintain the view that Japan\\'s economy remains in a minor adjustment phase in an upward climb, and we will monitor developments carefully,\" said economy minister Heizo Takenaka. But in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead, observers were less sanguine. \"It\\'s painting a picture of a recovery... much patchier than previously thought,\" said Paul Sheard, economist at Lehman Brothers in Tokyo. Improvements in the job market apparently have yet to feed through to domestic demand, with private consumption up just 0.2% in the third quarter.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "727900dc-6b51-4594-8347-1f088a6a2deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\e175932\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b68160d-884a-464a-b498-73c22b20651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect counts:\n",
    "probs = {} # key: (w(t-1), w(t+1), value: {w(t): count(w(t))})\n",
    "for doc in texts:\n",
    "    lines = doc.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        tokens = word_tokenize(line)\n",
    "        for i in range(len(tokens) - 2):\n",
    "            t_0 = tokens[i]\n",
    "            t_1 = tokens[i+1]\n",
    "            t_2 = tokens[i +2]\n",
    "            key = (t_0, t_2)\n",
    "            if key not in probs:\n",
    "                probs[key] = {}\n",
    "            # add count for middle token\n",
    "            if t_1 not in probs[key]:\n",
    "                probs[key][t_1] = 1\n",
    "            else: \n",
    "                probs[key][t_1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5a01ade-552d-44de-9dd4-957c1c140187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize probabilities \n",
    "for key, d in probs.items():\n",
    "    # d should represent a distribution\n",
    "    total = sum(d.values())\n",
    "    for k, v in d.items():\n",
    "        d[k] = v/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bfb97a7-f729-4c92-b0ab-86f22b82fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Ad', 'boost'): {'sales': 1.0},\n",
       " ('sales', 'Time'): {'boost': 1.0},\n",
       " ('boost', 'Warner'): {'Time': 1.0},\n",
       " ('Time', 'profit'): {'Warner': 1.0},\n",
       " ('Warner', 'Quarterly'): {'profit': 1.0},\n",
       " ('profit', 'profits'): {'Quarterly': 1.0},\n",
       " ('Quarterly', 'at'): {'profits': 1.0},\n",
       " ('profits', 'US'): {'at': 1.0},\n",
       " ('at', 'media'): {'US': 1.0},\n",
       " ('US', 'giant'): {'media': 0.1,\n",
       "  'telecoms': 0.1,\n",
       "  'banking': 0.2,\n",
       "  'foods': 0.1,\n",
       "  'retail': 0.1,\n",
       "  'oil': 0.2,\n",
       "  'mortgage': 0.1,\n",
       "  'agrochemical': 0.1}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(probs.items())[:10]) #checking probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e7e6f6c-5a03-46a2-b2a9-47e1b97020c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spin_document(doc):\n",
    "    #split the document into lines(paragrah)\n",
    "    lines = doc.split(\"\\n\")\n",
    "    output = []\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            new_line = spin_line(line)\n",
    "        else:\n",
    "            new_line = line\n",
    "        output.append(new_line)\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a65fd0e-3e28-4df2-8ac1-9d92b75f6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenizer = TreebankWordDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dddea806-1d4b-44fd-bb98-9e7cc28a048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'].iloc[0].split(\"\\n\")[2] #checking one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f23e9a07-9044-4816-a8f2-b177bb1dd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detokenizer.detokenize(word_tokenize(df['text'].iloc[0].split(\"\\n\")[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "224c2e25-a382-4078-916e-9d036fddfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cummulative = 0\n",
    "    for t, p in d.items():\n",
    "        cummulative += p \n",
    "        if p0 < cummulative:\n",
    "            return t\n",
    "    assert(False) # should never get there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "049db8bf-17dd-4b02-bee3-a3d20d602831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize\n",
    "def spin_line(line):\n",
    "    tokens = word_tokenize(line)\n",
    "    i = 0 \n",
    "    output = [tokens[0]]\n",
    "    while i < (len(tokens) - 2):\n",
    "        t_0 = tokens[i]\n",
    "        t_1 = tokens[i + 1]\n",
    "        t_2 = tokens[i + 2]\n",
    "        key = (t_0, t_2)\n",
    "        p_dist = probs[key]\n",
    "        if len(p_dist) > 1 and np.random.random() < 0.3:\n",
    "            #let's replace the middle word\n",
    "            middle = sample_word(p_dist)\n",
    "            output.append(t_1)\n",
    "            output.append(\"<\" + middle + \">\")\n",
    "            output.append(t_2)\n",
    "            \n",
    "            #we wont replace the 3rd token since the middle \n",
    "            # token was dependent on it \n",
    "            # instead, skp ahead 2 steps \n",
    "            i += 2\n",
    "        else:\n",
    "            # we wont replace this middle word \n",
    "            output.append(t_1)\n",
    "            i += 1\n",
    "    # append the final token  - only if there is no replacement\n",
    "    if i == len(tokens) - 2:\n",
    "        output.append(tokens[-1])\n",
    "    return detokenizer.detokenize(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28a4fc35-2fd9-4797-a49b-8f80808daddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(texts.shape[0])\n",
    "doc = texts.iloc[i]\n",
    "new_doc = spin_document(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "747d2bfa-e023-436a-b38b-ad8ca24a2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Golden economic period' to end Ten years of <.> \"golden\n",
      "<significant>\" economic performance may come <choose> to an end\n",
      "<improvement> in 2005 with growth slowing markedly, City <City>\n",
      "consultancy Deloitte has warned . The UK economy could suffer a\n",
      "backlash <quarter> from the slowdown <dip> in the housing market,\n",
      "triggering <despite> a fall in consumer <consumer> spending and <and>\n",
      "a rise in unemployment . Deloitte is forecasting economic growth of 2\n",
      "<5.1>% this year <quarter>, below Chancellor Gordon Brown's forecast\n",
      "<purchase> of 3% <%> to 3.5% . It <It> also believes <recommends> that\n",
      "interest rates will fall to 4 <29>% by <of> the end of <of> the year\n",
      "<increase>. In its quarterly <likely> economic review <growth>,\n",
      "Deloitte <analysts> said the UK economy had enjoyed a \"golden period\"\n",
      "during the past decade with unemployment falling to a <a> near 30 year\n",
      "low and inflation at its lowest <highest> since the 1960s . But it\n",
      "<it> warned that this growth had been achieved at <at> the expense of\n",
      "creating <what> major \"imbalances\" in the economy . Deloitte's chief\n",
      "economic advisor Roger Bootle said: <.> \"The <The> biggest hit of all\n",
      "is set <expected> to come <449,603> from the housing market which has\n",
      "already embarked <lives> on a major slowdown <slowdown>. \"Whereas the\n",
      "main driver <target> of the <the> economy in recent years has been\n",
      "robust household spending growth, this is likely to suffer as the\n",
      "housing market slowdown gathers pace .\" Economic growth is <are>\n",
      "likely to be constrained during the next <past> few years by increased\n",
      "pressure on household budgets and rising taxes <taxes>, Deloitte\n",
      "believes . Gordon Brown will need <need> to raise about $10bn a year\n",
      "in order <attempt> to sustain the public finances <finances> in the\n",
      "short term, <,> the firm claims <Quiksilver>. This will result in <in>\n",
      "a marked <rapid> slowdown in growth <expanding> in 2005 and 2006\n",
      "compared to last year, <ago> when the economy expanded by 3.25 <1.1>%\n",
      ". However, Deloitte stressed that the slowdown was unlikely to have\n",
      "<produce> any major impact on retail <retail> prices while it expected\n",
      "<is> the Bank of England <lying> to respond <respond> quickly to signs\n",
      "<allies> of the economy faltering <\">. It expects a series of\n",
      "\"aggressive <missing>\" interest rate cuts over the next <previous> two\n",
      "years, with <or> the cost of borrowing falling from its <its> current\n",
      "4.75% mark to 3.5 <2.3>% by the end <number> of 2006 . \"<\"> Although\n",
      "2005 may not be the year when things go completely wrong, it will\n",
      "probably mark the start of a more difficult period for the UK economy,\n",
      "<.>\" Mr Bootle <Putin>.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(\n",
    "    new_doc, replace_whitespace = False, fix_sentence_endings = True\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
